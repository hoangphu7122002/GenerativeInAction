{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmjMn23j1bhs",
        "outputId": "95239fde-1282-43a1-8175-aadafee077ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fcb1abd2a30>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST # Training dataset\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "torch.manual_seed(0) # Set for testing purposes, please do not change!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HelperFunction**"
      ],
      "metadata": {
        "id": "JmaeveuF14vP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()\n",
        "\n",
        "def get_noise(n_samples, z_dim = 10,device = 'cpu'):\n",
        "    return torch.randn(n_samples,z_dim,device = device)"
      ],
      "metadata": {
        "id": "dhbPaGs312Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generator**"
      ],
      "metadata": {
        "id": "eXaKeBz12MXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generator_block(input_dim,output_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_dim,output_dim),\n",
        "        nn.BatchNorm1d(output_dim),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,z_dim = 10,im_dim = 28 * 28,hidden_dim = 128):\n",
        "        super(Generator,self).__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            get_generator_block(z_dim,hidden_dim),\n",
        "            get_generator_block(hidden_dim,hidden_dim * 2),\n",
        "            get_generator_block(hidden_dim * 2,hidden_dim * 4),\n",
        "            get_generator_block(hidden_dim * 4,hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8,im_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self,noise):\n",
        "        return self.gen(noise)\n",
        "    \n",
        "    def get_gen(self):\n",
        "        return self.gen"
      ],
      "metadata": {
        "id": "0YVJAW0r2NZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test architect\n",
        "a = Generator().get_gen()\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzD0ZSbl4bIt",
        "outputId": "88e72e79-5eab-4ca9-9c11-27a8ad48a072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=128, bias=True)\n",
            "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Linear(in_features=1024, out_features=784, bias=True)\n",
            "  (5): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discriminator**"
      ],
      "metadata": {
        "id": "C679_crq43aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator_block(input_dim,output_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_dim,output_dim),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,im_dim = 28 * 28,hidden_dim = 128):\n",
        "        super(Discriminator,self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            get_discriminator_block(im_dim,hidden_dim * 4),\n",
        "            get_discriminator_block(hidden_dim * 4,hidden_dim * 2),\n",
        "            get_discriminator_block(hidden_dim * 2,hidden_dim),\n",
        "            nn.Linear(hidden_dim,1)\n",
        "        )\n",
        "    \n",
        "    def forward(self,image):\n",
        "        return self.disc(image)\n",
        "    \n",
        "    def get_disc(self):\n",
        "        return self.disc"
      ],
      "metadata": {
        "id": "Nnrl4MrA44yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test architect\n",
        "b = Discriminator().get_disc()\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJZuq-sT6T4M",
        "outputId": "2a6bc8c9-8a98-4261-c693-24bd155a215f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (3): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialize Component**"
      ],
      "metadata": {
        "id": "9Bnjgr7N6xGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set hyperparameter\n",
        "z_dim = 64\n",
        "batch_size = 128\n",
        "n_epochs = 200\n",
        "display_step = 500\n",
        "lr = 0.00001\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#convert data to tensor\n",
        "dataloader = DataLoader(\n",
        "    MNIST('.', download=True, transform=transforms.ToTensor()),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "#set device\n",
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "4mWSQRWW6zQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimize\n",
        "\n",
        "gen = Generator(z_dim).to(device)\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
        "disc = Discriminator().to(device) \n",
        "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "KGiOy1OY7xKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Method**"
      ],
      "metadata": {
        "id": "od5x_g1G8Rcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n",
        "    fake_noise = get_noise(num_images,z_dim,device)\n",
        "    fake_img = gen(fake_noise)\n",
        "    disc_fake_pred = disc(fake_img.detach()) #to unaffect parameter of generator\n",
        "    disc_fake_loss = criterion(disc_fake_pred,torch.zeros_like(disc_fake_pred))\n",
        "    disc_real_pred = disc(real.detach())\n",
        "    disc_real_loss = criterion(disc_real_pred,torch.ones_like(disc_real_pred))\n",
        "    disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
        "\n",
        "    return disc_loss\n",
        "\n",
        "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
        "    fake_noise = get_noise(num_images,z_dim,device)\n",
        "    fake_image = gen(fake_noise)\n",
        "    disc_fake_pred = disc(fake_image)\n",
        "    gen_loss = criterion(disc_fake_pred,torch.ones_like(disc_fake_pred))\n",
        "\n",
        "    return gen_loss  "
      ],
      "metadata": {
        "id": "ooWj7MAb8XNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "gWmCEXbg-30e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#some setup parameter\n",
        "\n",
        "cur_step = 0\n",
        "mean_generator_loss = 0\n",
        "mean_discriminator_loss = 0\n",
        "test_generator = True # Whether the generator should be tested\n",
        "gen_loss = False\n",
        "error = False"
      ],
      "metadata": {
        "id": "fqr1K5Z2-4-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "    for real, _ in tqdm(dataloader):\n",
        "        cur_batch_size = len(real)\n",
        "\n",
        "        # Flatten the batch of real images from the dataset\n",
        "        real = real.view(cur_batch_size, -1).to(device)\n",
        "        \n",
        "        ### Update discriminator ###\n",
        "\n",
        "        disc_opt.zero_grad() #zero_out the gradient before backpropagation\n",
        "\n",
        "        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n",
        "        disc_loss.backward(retain_graph = True)\n",
        "\n",
        "        disc_opt.step()\n",
        "\n",
        "        ### Update discriminator ###\n",
        "        \n",
        "        #no-understand\n",
        "        # For testing purposes, to keep track of the generator weights\n",
        "        if test_generator:\n",
        "            old_generator_weights = gen.gen[0][0].weight.detach().clone()\n",
        "\n",
        "        ### Update generator ###\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "\n",
        "        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n",
        "        gen_loss.backward(retain_graph = True)\n",
        "\n",
        "        gen_opt.step()\n",
        "         \n",
        "        ### Update discriminator ###\n",
        "\n",
        "        # For testing purposes, to check that your code changes the generator weights\n",
        "        if test_generator:\n",
        "            try:\n",
        "                assert lr > 0.0000002 or (gen.gen[0][0].weight.grad.abs().max() < 0.0005 and epoch == 0)\n",
        "                assert torch.any(gen.gen[0][0].weight.detach().clone() != old_generator_weights)\n",
        "            except:\n",
        "                error = True\n",
        "                print(\"Runtime tests have failed\")\n",
        "        \n",
        "        # Keep track of the average discriminator loss\n",
        "        mean_discriminator_loss += disc_loss.item() / display_step\n",
        "\n",
        "        # Keep track of the average generator loss\n",
        "        mean_generator_loss += gen_loss.item() / display_step\n",
        "\n",
        "        ### Visualization code ###\n",
        "        if cur_step % display_step == 0 and cur_step > 0:\n",
        "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
        "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
        "            fake = gen(fake_noise)\n",
        "            show_tensor_images(fake)\n",
        "            show_tensor_images(real)\n",
        "            mean_generator_loss = 0\n",
        "            mean_discriminator_loss = 0\n",
        "        cur_step += 1"
      ],
      "metadata": {
        "id": "xrd5Yylz_HY2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}